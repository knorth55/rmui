<launch>
  <arg name="audio_topic" default="/audio_remote" />
  <arg name="audio_info_topic" default="/audio_info_remote" />
  <arg name="voice_topic" default="/text_to_speech" />
  <arg name="n_channel" default="1" />
  <arg name="depth" default="16" />
  <arg name="sample_rate" default="16000" />
  <arg name="device" default=""  />
  <arg name="engine" default="Google" />
  <arg name="language" default="en-US" />
  <arg name="continuous" default="false"  />

  <!-- audio capture -->
  <node name="audio_capture" pkg="audio_capture" type="audio_capture"
        respawn="true">
    <remap from="/audio" to="$(arg audio_topic)" />
    <remap from="/audio_info" to="$(arg audio_info_topic)" />
    <rosparam subst_value="true">
      format: wave
      channels: $(arg n_channel)
      depth: $(arg depth)
      sample_rate: $(arg sample_rate)
    </rosparam>
    <param name="device" value="$(arg device)" />
  </node>

  <node name="speech_recognition"
        pkg="ros_speech_recognition" type="speech_recognition_node.py"
        respawn="true"
        output="screen">
    <rosparam subst_value="true">
      audio_topic: $(arg audio_topic)
      voice_topic: $(arg voice_topic)
      n_channel: $(arg n_channel)
      depth: $(arg depth)
      sample_rate: $(arg sample_rate)
      engine: $(arg engine)
      language: $(arg language)
      continuous: $(arg continuous)
    </rosparam>
  </node>

  <!-- soundplay -->
  <node name="remote_soundplay_node"
        pkg="sound_play" type="soundplay_node.py">
    <remap from="robotsound" to="remotesound" />
    <remap from="sound_play" to="remotesound" />
  </node>
  <node name="remote_soundplay_jp_node"
        pkg="sound_play" type="soundplay_node.py">
    <remap from="robotsound" to="remotesound_jp" />
    <remap from="sound_play" to="remotesound_jp" />
  </node>
</launch>
